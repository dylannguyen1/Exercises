{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task of data engineer\n",
    "Set up scheduled ingestion of data from the application databases to an analytical database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Engineer:\n",
    "    - Cloud technology\n",
    "    - Develop Scalable Data Architecture\n",
    "    - Streamline Data Acquisition\n",
    "    - Set up processes to bring together data\n",
    "    - Clear Corrupted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist: \n",
    "    - Mining data for pattern\n",
    "    - Apply statistical models on large datasets\n",
    "    - Build predictive models using ML\n",
    "    - Develop tools to monitor business process\n",
    "    - Clean outliers in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Engineer Problem:\n",
    "\n",
    "###Data scientists are querying the online store databases directly and slowing down the functioning of the application since it's using the same database. ###\n",
    "Data Engineer should make sure there is a seperate database for analytic\n",
    "\n",
    "###The online store is slow because the application's database server doesn't have enough memory.### infrastructure problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools of data engineer\n",
    "#Processing example\n",
    "##cluster of computers perform these operations using PySpark framework\n",
    "\n",
    "df = spark.read.parquet(\"users.parquet\") \n",
    "\n",
    "outliers = df.filter(df[\"age\"] > 100)\n",
    "\n",
    "print(outliers.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing tasks\n",
    "- Data engineers often have to join, clean, or organize data before loading it into a destination analytics database. This is done in the data processing, or data transformation step.\n",
    "- Data Processing is distributed over clusters of virtual machines(e.g. using Spark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling tools\n",
    "\n",
    "Make sure jobs run in a specific order and all dependencies are resolved correctly.\n",
    "\n",
    "Make sure the jobs run at midnight UTC each day.\n",
    "\n",
    "###Scale up the number of nodes when there's lots of data to be processed.### Jobs of processing tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Cloud computing ?\n",
    "\n",
    "The cloud can provide you with the resources you need, when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Data engineering toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Databases: A usually large collection of data organized especially for rapid search and retrieval\n",
    "\n",
    "- Holds data\n",
    "- Organise data\n",
    "- Retrieve/ Search Data\n",
    "Database management system- \n",
    "DBMS -much more organised than file systems\n",
    "- functitons: search, replication\n",
    "Structured vs unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL database schema:\n",
    "    \n",
    "## Create Customer table\n",
    "    CREATE TABLE \"Customer\"(\n",
    "    \"id\" SERIAL not NULL,\n",
    "    \"first_name\" varchar,\n",
    "    \"second_name\" varchar,\n",
    "    PRIMARY KEY (\"id\")\n",
    "    )\n",
    "    \n",
    "## Create order table\n",
    "    CREATE TABLE \"Order\"(\n",
    "    \"id\" SERIAL not NULL,\n",
    "    \"customer_id\" integer REFERENCES \" Customer\",\n",
    "    \"product_name\" varchar,\n",
    "    \"product_price\" integer,\n",
    "        \n",
    "    PRIMARY KEY(\"id\")\n",
    "    )\n",
    "\n",
    "SELECT * FROM \"Customer\"\n",
    "INNER JOIN \"Order\"\n",
    "ON \"customer_id\" = \"Customer\" .\"id\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL:\n",
    "    - Customer data in a store's database\n",
    "    - Always has a database schema\n",
    "    - MySQL, PostgreSQL\n",
    "    \n",
    "NoSQL:\n",
    "    - can be schemaless\n",
    "    - Key- value stores: Redis e.g. catching layer in distributed web server\n",
    "    - MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The database schema\n",
    "\n",
    "#db_engine: database engine, which has been defined for you and is called db_engine\n",
    "#db_enginer = Engine(postgresql://repl@/postgres)    \n",
    "\n",
    "#Complete the SELECT statement\n",
    "\n",
    "data = pd.read_sql(\"\"\"\n",
    "SELECT first_name, last_name FROM \"Customer\"\n",
    "ORDER BY last_name, first_name\n",
    "\"\"\", db_engine)\n",
    "\n",
    "#Show the first 3 rows of the DataFrame\n",
    "\n",
    "print(data.head(n=3))\n",
    "\n",
    "#Show the info of the DataFrame\n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Complete the SELECT statement\n",
    "\n",
    "data = pd.read_sql(\"\"\"\n",
    "\n",
    "SELECT * FROM \"Customer\"\n",
    "\n",
    "INNER JOIN \"Order\"\n",
    "\n",
    "ON \"Order\".\"customer_id\"=\"Customer\".\"id\"\n",
    "\n",
    "\"\"\", db_engine)\n",
    "\n",
    "#Show the id column of data\n",
    "print(data.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parallel computing\n",
    "Parallel computing can optimize the use of multiple processing units.\n",
    "Parallel computing can optimize the use of memory between several machines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.Pool\n",
    "from multiprocessing import Tool\n",
    "## function take_mean_Age\n",
    "def take_mean_age(year_and_group):\n",
    "    year, group = year_and_group\n",
    "    return pd.DataFrame({\"Age\":group['Age'].mean()}, index = [year])\n",
    "\n",
    "with Pool(4) as p: ##using 4 cores\n",
    "    results = p.map(take_mean_age, athlete_events.groupby(\"Year\"))\n",
    "    \n",
    "## concatenate the results to form the resulting DataFrame\n",
    "result_df = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dask framework to avoid write low-level code\n",
    "import dask.dataframe as dd\n",
    "\n",
    "## partition dataframe into 4\n",
    "athlete_events_dask = dd.from_pandas(athlete_events, npartitions = 4)\n",
    "\n",
    "## Run parallel computations from each partition\n",
    "result_df = athlete_events_dask.groupby(\"Year\").Age.mean().compute() ## dask use lazy evaluation hence add.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From task to subtasks\n",
    "# Function to apply a function over multiple cores\n",
    "@print_timing\n",
    "#It takes in as input the function being applied, the grouping used, and the number of cores needed for the analysis.\n",
    "def parallel_apply(apply_func, groups, nb_cores):\n",
    "    with Pool(nb_cores) as p:\n",
    "        results = p.map(apply_func, groups)\n",
    "    return pd.concat(results)\n",
    "\n",
    "# Parallel apply using 1 core\n",
    "parallel_apply(take_mean_age, athlete_events.groupby('Year'), nb_cores = 1)\n",
    "\n",
    "# Parallel apply using 2 cores\n",
    "parallel_apply(take_mean_age, athlete_events.groupby('Year'), nb_cores = 2)\n",
    "\n",
    "# Parallel apply using 4 cores\n",
    "parallel_apply(take_mean_age, athlete_events.groupby('Year'), nb_cores = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>Nstor Abad Sanjun</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>167.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>Antonio Abadia Beci</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>170.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>Abubakar Abbas Abbas</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>175.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>Forough Abbasi</td>\n",
       "      <td>F</td>\n",
       "      <td>20</td>\n",
       "      <td>164.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>251</td>\n",
       "      <td>Bashir Abdi</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>176.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                  name gender  age  height  weight\n",
       "0   51     Nstor Abad Sanjun      M   23   167.0    64.0\n",
       "1   55   Antonio Abadia Beci      M   26   170.0    65.0\n",
       "2  110  Abubakar Abbas Abbas      M   20   175.0    66.0\n",
       "3  126        Forough Abbasi      F   20   164.0    58.0\n",
       "4  251           Bashir Abdi      M   27   176.0    56.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "athlete_events = pd.read_csv(\"athletes.xls\")\n",
    "athlete_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using a dataframe \n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Set the number of pratitions\n",
    "athlete_events_dask = dd.from_pandas(athlete_events, npartitions = 4)\n",
    "\n",
    "# Calculate the mean Age per Year\n",
    "print(athlete_events_dask.groupby('Year').Age.mean().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parallel computation framework\n",
    "# Hive Example\n",
    "SELECT year,AVG(age)\n",
    "FROM views.athlete_events\n",
    "GROUP BY year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
